"use strict";(self.webpackChunkzeuz_docs=self.webpackChunkzeuz_docs||[]).push([[5099],{4645:(e,s,t)=>{t.d(s,{A:()=>r});const r=t.p+"assets/images/data-storage-5548e2cf2ba4c9681d21ac032905fda4.png"},5303:(e,s,t)=>{t.d(s,{A:()=>r});const r=t.p+"assets/images/pbc-data-c149612bed67b013016fd02fbfceb196.png"},28453:(e,s,t)=>{t.d(s,{R:()=>a,x:()=>o});var r=t(96540);const i={},n=r.createContext(i);function a(e){const s=r.useContext(n);return r.useMemo((function(){return"function"==typeof e?e(s):{...s,...e}}),[s,e])}function o(e){let s;return s=e.disableParentContext?"function"==typeof e.components?e.components(i):e.components||i:a(e.components),r.createElement(n.Provider,{value:s},e.children)}},31875:(e,s,t)=>{t.d(s,{A:()=>r});const r=t.p+"assets/images/build-count-722b03b5e2843d9a2545f39713f28646.png"},37872:(e,s,t)=>{t.d(s,{A:()=>r});const r=t.p+"assets/images/easily-automatable-a913e5ad1ee4c0f24d4824205fc20c0f.png"},41735:(e,s,t)=>{t.d(s,{A:()=>r});const r=t.p+"assets/images/pbc-chart-9f3f08e429234254e2ccb98db705966b.png"},42171:(e,s,t)=>{t.d(s,{A:()=>r});const r=t.p+"assets/images/recent-build-dfacb713954bbdd82bc92c1e4c50e951.png"},46749:(e,s,t)=>{t.d(s,{A:()=>r});const r=t.p+"assets/images/previous-build-2998b5754a51379ed3f35070cdf0f6c8.png"},51867:(e,s,t)=>{t.d(s,{A:()=>r});const r=t.p+"assets/images/orphaned-test-cases-e573c563b40756d0476a18d79c2a90a8.png"},71315:(e,s,t)=>{t.d(s,{A:()=>r});const r=t.p+"assets/images/build-comparison-78102dad5b0fc2af10b6907ae3be4045.png"},78921:(e,s,t)=>{t.d(s,{A:()=>r});const r=t.p+"assets/images/Dashboard-69954c4b57766516d44dc63013817879.png"},81784:(e,s,t)=>{t.d(s,{A:()=>r});const r=t.p+"assets/images/available-storage-ba833fe9491c13cda9d6de75d5fad23a.png"},83841:(e,s,t)=>{t.r(s),t.d(s,{assets:()=>h,contentTitle:()=>d,default:()=>u,frontMatter:()=>o,metadata:()=>r,toc:()=>l});const r=JSON.parse('{"id":"zeuz-server/dashboard-page","title":"Dashboard Page","description":"The Dashboard page is the main overview screen of a software platform that displays key information, metrics, and summaries in a single place. It gives users a quick understanding of the current status of their projects, tests, or system health.","source":"@site/docs/zeuz-server/dashboard-page.md","sourceDirName":"zeuz-server","slug":"/zeuz-server/dashboard-page","permalink":"/docs/zeuz-server/dashboard-page","draft":false,"unlisted":false,"tags":[],"version":"current","sidebarPosition":1,"frontMatter":{"id":"dashboard-page","title":"Dashboard Page","sidebar_position":1},"sidebar":"docsSidebar","previous":{"title":"ZeuZ Server","permalink":"/docs/category/zeuz-server"},"next":{"title":"Zeuz Server Sitemap","permalink":"/docs/zeuz-server/zeuz-server-sitemap"}}');var i=t(74848),n=t(28453);t(96540);const a=({children:e,color:s,textColor:t})=>(0,i.jsx)("span",{style:{backgroundColor:s||"inherit",borderRadius:"4px",color:t||"#fff",padding:"0.2rem"},children:e}),o={id:"dashboard-page",title:"Dashboard Page",sidebar_position:1},d=void 0,h={},l=[{value:"Explanation of the Dashboard Page",id:"explanation-of-the-dashboard-page",level:2},{value:"ZeuZ Node Area",id:"zeuz-node-area",level:3},{value:"Build Health",id:"build-health",level:3},{value:"Example",id:"example",level:3},{value:"Automatability",id:"automatability",level:3},{value:"Automatability Categories",id:"automatability-categories",level:4},{value:"Build Comparison",id:"build-comparison",level:3},{value:"Example",id:"example-1",level:3},{value:"PBC (Priority Based Comparison)",id:"pbc-priority-based-comparison",level:3},{value:"Example",id:"example-2",level:3},{value:"Test Case Create Velocity",id:"test-case-create-velocity",level:3},{value:"Scheduler Health",id:"scheduler-health",level:3},{value:"Orphaned Test Cases",id:"orphaned-test-cases",level:3},{value:"Storage",id:"storage",level:3}];function c(e){const s={admonition:"admonition",br:"br",em:"em",h2:"h2",h3:"h3",h4:"h4",hr:"hr",img:"img",li:"li",p:"p",strong:"strong",table:"table",tbody:"tbody",td:"td",th:"th",thead:"thead",tr:"tr",ul:"ul",...(0,n.R)(),...e.components};return(0,i.jsxs)(i.Fragment,{children:[(0,i.jsx)(s.p,{children:"The Dashboard page is the main overview screen of a software platform that displays key information, metrics, and summaries in a single place. It gives users a quick understanding of the current status of their projects, tests, or system health."}),"\n",(0,i.jsx)(s.p,{children:(0,i.jsx)(s.img,{src:t(78921).A+"",width:"1877",height:"1872"})}),"\n",(0,i.jsx)(s.hr,{}),"\n",(0,i.jsx)(s.h2,{id:"explanation-of-the-dashboard-page",children:"Explanation of the Dashboard Page"}),"\n",(0,i.jsx)(s.h3,{id:"zeuz-node-area",children:"ZeuZ Node Area"}),"\n",(0,i.jsx)(s.p,{children:(0,i.jsx)(s.strong,{children:"1. ZeuZ Node Description Box"})}),"\n",(0,i.jsxs)(s.ul,{children:["\n",(0,i.jsxs)(s.li,{children:[(0,i.jsx)(s.strong,{children:"Text"}),": ",(0,i.jsx)(s.em,{children:'"ZeuZ Node is the automation engine working behind the scenes to power your test executions".'})]}),"\n",(0,i.jsx)(s.li,{children:"This means the ZeuZ Node is responsible for executing automated tests locally or on remote systems."}),"\n"]}),"\n",(0,i.jsx)(s.p,{children:(0,i.jsx)(s.strong,{children:"2. Download Button"})}),"\n",(0,i.jsxs)(s.ul,{children:["\n",(0,i.jsx)(s.li,{children:'Labelled "Download ZeuZ Node", this button allows users to download the node installer or package.'}),"\n"]}),"\n",(0,i.jsx)(s.p,{children:(0,i.jsx)(s.strong,{children:"3. Navigation Tiles"})}),"\n",(0,i.jsxs)(s.ul,{children:["\n",(0,i.jsxs)(s.li,{children:[(0,i.jsx)(s.strong,{children:"Node"}),": Node setup and usage."]}),"\n",(0,i.jsxs)(s.li,{children:[(0,i.jsx)(s.strong,{children:"Server"}),": Server configuration and monitoring."]}),"\n",(0,i.jsxs)(s.li,{children:[(0,i.jsx)(s.strong,{children:"Changelog"}),": Shows version updates and improvements."]}),"\n",(0,i.jsxs)(s.li,{children:[(0,i.jsx)(s.strong,{children:"Docs"}),": Opens the full documentation for user guidance."]}),"\n"]}),"\n",(0,i.jsx)(s.p,{children:(0,i.jsx)(s.img,{src:t(91856).A+"",width:"1234",height:"173"})}),"\n",(0,i.jsx)(s.hr,{}),"\n",(0,i.jsx)(s.h3,{id:"build-health",children:"Build Health"}),"\n",(0,i.jsx)(s.p,{children:"Build Health refers to the overall quality and stability of a software build, as determined by the results of automated or manual test cases executed during the build process. It is basically a chart showing the pass and fail status of the current build."}),"\n",(0,i.jsx)(s.p,{children:"There are two tabs at the top:"}),"\n",(0,i.jsxs)(s.p,{children:[(0,i.jsx)(s.strong,{children:"1. Milestone"}),": This suggests that the build health can be viewed in the context of specific milestones (e.g., stages or goals in a project).",(0,i.jsx)(s.br,{}),"\n",(0,i.jsx)(s.strong,{children:"2. Version"}),": This suggests that the build health can also be viewed in the context of specific versions (e.g., releases or iterations of the software)."]}),"\n",(0,i.jsx)(s.p,{children:"Build Health displays two key metrics, such as:"}),"\n",(0,i.jsxs)(s.p,{children:[(0,i.jsx)(s.strong,{children:"1. Pass"}),": Indicates the percentage of tests or checks that passed successfully.",(0,i.jsx)(s.br,{}),"\n",(0,i.jsx)(s.strong,{children:"2. Fail"}),": Indicates the percentage of tests or checks that failed."]}),"\n",(0,i.jsxs)(s.p,{children:["However, when hovering over the ",(0,i.jsx)(s.strong,{children:"Pass"})," or ",(0,i.jsx)(s.strong,{children:"Fail"})," indicators, the system displays the corresponding percentage and count of test cases, providing a quick overview of build health."]}),"\n",(0,i.jsx)(s.admonition,{type:"note",children:(0,i.jsxs)(s.p,{children:['If the "Build Health" section shows ',(0,i.jsx)(s.strong,{children:"Pass"})," and ",(0,i.jsx)(s.strong,{children:"Fail"})," metrics with ",(0,i.jsx)(s.strong,{children:"NaN%"}),", then it indicates that the system lacks the necessary data to compute these percentages. This could be due to missing test results, a malfunctioning testing framework, or incomplete build processes. It also indicates that no test cases have been executed or recorded. To resolve this, ensure that tests are running and that the results are being captured and processed correctly."]})}),"\n",(0,i.jsx)(s.h3,{id:"example",children:"Example"}),"\n",(0,i.jsxs)(s.table,{children:[(0,i.jsx)(s.thead,{children:(0,i.jsx)(s.tr,{children:(0,i.jsx)(s.th,{children:"Build Health with Pass and Fail metrics"})})}),(0,i.jsx)(s.tbody,{children:(0,i.jsx)(s.tr,{children:(0,i.jsx)(s.td,{children:(0,i.jsx)(s.img,{src:t(31875).A+"",width:"703",height:"207"})})})})]}),"\n",(0,i.jsx)(s.hr,{}),"\n",(0,i.jsx)(s.h3,{id:"automatability",children:"Automatability"}),"\n",(0,i.jsxs)(s.p,{children:["Automatability refers to how easily and effectively a test can be automated using automation tools or frameworks. In this context, the chart shown is a ",(0,i.jsx)(s.strong,{children:"Donut chart"}),", which is commonly used to represent proportions or distributions. The chart is divided into segments, each representing a different category of automatability."]}),"\n",(0,i.jsx)(s.h4,{id:"automatability-categories",children:"Automatability Categories"}),"\n",(0,i.jsxs)(s.table,{children:[(0,i.jsx)(s.thead,{children:(0,i.jsxs)(s.tr,{children:[(0,i.jsx)(s.th,{children:"Category"}),(0,i.jsx)(s.th,{children:"Color"})]})}),(0,i.jsxs)(s.tbody,{children:[(0,i.jsxs)(s.tr,{children:[(0,i.jsx)(s.td,{children:"Automated"}),(0,i.jsx)(s.td,{children:(0,i.jsx)(a,{color:"rgb(37, 211, 102)",children:"Green"})})]}),(0,i.jsxs)(s.tr,{children:[(0,i.jsx)(s.td,{children:"Easily Automated"}),(0,i.jsx)(s.td,{children:(0,i.jsx)(a,{color:"rgb(51, 204, 204)",children:"Cyan"})})]}),(0,i.jsxs)(s.tr,{children:[(0,i.jsx)(s.td,{children:"Hard to Automate"}),(0,i.jsx)(s.td,{children:(0,i.jsx)(a,{color:"rgb(255, 152, 0)",children:"Orange"})})]}),(0,i.jsxs)(s.tr,{children:[(0,i.jsx)(s.td,{children:"Not Automatable"}),(0,i.jsx)(s.td,{children:(0,i.jsx)(a,{color:"rgb(254, 41, 147)",children:"Hot Pink"})})]}),(0,i.jsxs)(s.tr,{children:[(0,i.jsx)(s.td,{children:"Performance"}),(0,i.jsx)(s.td,{children:(0,i.jsx)(a,{color:"rgb(127, 40, 255)",children:"Purple"})})]}),(0,i.jsxs)(s.tr,{children:[(0,i.jsx)(s.td,{children:"Undefined"}),(0,i.jsx)(s.td,{children:(0,i.jsx)(a,{color:"rgb(158, 158, 158)",children:"Gray"})})]})]})]}),"\n",(0,i.jsxs)(s.p,{children:["Under our server, test cases are categorized based on their level of automatability. This shows how many test cases are automated, easy to automate, hard to automate, not automatable, performance-related, or undefined. When hovering over each segment of a chart, it shows how many test cases belong to that category, along with their percentage. For example, there are ",(0,i.jsx)(s.strong,{children:"3,294 automated test cases (95.06%)"})," and ",(0,i.jsx)(s.strong,{children:"133 test cases that are easy to automate (3.84%)"}),". Similar data is displayed for the remaining categories as well."]}),"\n",(0,i.jsx)(s.p,{children:(0,i.jsx)(s.img,{src:t(37872).A+"",width:"542",height:"401"})}),"\n",(0,i.jsx)(s.hr,{}),"\n",(0,i.jsx)(s.h3,{id:"build-comparison",children:"Build Comparison"}),"\n",(0,i.jsx)(s.p,{children:"Build Comparison refers to the process of comparing the test results of two or more software builds to identify changes in quality, functionality, or performance overtime."}),"\n",(0,i.jsx)(s.p,{children:"This chart displays a comparison of the last five builds. It shows how many test cases were submitted and passed in previous versions or milestones, and how many have passed in recent builds, etc. The purpose is to provide a clear comparison."}),"\n",(0,i.jsx)(s.h3,{id:"example-1",children:"Example"}),"\n",(0,i.jsxs)(s.p,{children:["Users can observe that in an earlier build, ",(0,i.jsx)(s.strong,{children:"1616 test cases passed"}),"\r\nwhile ",(0,i.jsx)(s.strong,{children:"61 test cases failed"}),". And in the most recent build, ",(0,i.jsx)(s.strong,{children:"1806 test cases passed"})," and\r\n",(0,i.jsx)(s.strong,{children:"61 test cases failed"}),"."]}),"\n",(0,i.jsxs)(s.table,{children:[(0,i.jsx)(s.thead,{children:(0,i.jsxs)(s.tr,{children:[(0,i.jsx)(s.th,{children:"Previous Build"}),(0,i.jsx)(s.th,{children:"Recent Build"})]})}),(0,i.jsx)(s.tbody,{children:(0,i.jsxs)(s.tr,{children:[(0,i.jsx)(s.td,{children:(0,i.jsx)(s.img,{src:t(46749).A+"",width:"719",height:"601"})}),(0,i.jsx)(s.td,{children:(0,i.jsx)(s.img,{src:t(42171).A+"",width:"731",height:"609"})})]})})]}),"\n",(0,i.jsxs)(s.p,{children:["This helps determine whether the quality is improving or degrading overtime.",(0,i.jsx)(s.br,{}),"\n","At the top, there are toggle options for ",(0,i.jsx)(s.strong,{children:"Milestone"})," and ",(0,i.jsx)(s.strong,{children:"Version"}),". When ",(0,i.jsx)(s.strong,{children:"Milestone"})," is selected, the build comparison is shown based on milestones. When ",(0,i.jsx)(s.strong,{children:"Version"})," is selected, the build comparison is shown based on version."]}),"\n",(0,i.jsx)(s.p,{children:(0,i.jsx)(s.img,{src:t(71315).A+"",width:"710",height:"589"})}),"\n",(0,i.jsx)(s.hr,{}),"\n",(0,i.jsx)(s.h3,{id:"pbc-priority-based-comparison",children:"PBC (Priority Based Comparison)"}),"\n",(0,i.jsx)(s.p,{children:"Priority Based Comparison refers to the process of comparing test results based on the priority levels assigned to test cases."}),"\n",(0,i.jsxs)(s.p,{children:["Priority Based Comparison (PBC) allows users to analyze test results based on different priority levels, such as ",(0,i.jsx)(s.strong,{children:"P1"}),", ",(0,i.jsx)(s.strong,{children:"P2"}),", ",(0,i.jsx)(s.strong,{children:"P3"})," and ",(0,i.jsx)(s.strong,{children:"P4"}),". When you hover over the chart, you can see the name of the current build or milestone being analyzed."]}),"\n",(0,i.jsx)(s.h3,{id:"example-2",children:"Example"}),"\n",(0,i.jsxs)(s.p,{children:["In the current build, if there are ",(0,i.jsx)(s.strong,{children:"286 test cases that passed"})," and ",(0,i.jsx)(s.strong,{children:"7 test cases that failed"}),", this comparison becomes especially important because ",(0,i.jsx)(s.strong,{children:"P1"})," test cases are considered critical. By organizing results by priority, users can quickly identify issues in high-priority areas."]}),"\n",(0,i.jsx)(s.p,{children:(0,i.jsx)(s.img,{src:t(5303).A+"",width:"1278",height:"608"})}),"\n",(0,i.jsxs)(s.p,{children:["The chart also shows how many test cases are ",(0,i.jsx)(s.strong,{children:"passing"}),", ",(0,i.jsx)(s.strong,{children:"failing"}),", ",(0,i.jsx)(s.strong,{children:"blocked"}),", ",(0,i.jsx)(s.strong,{children:"skipped"}),", or ",(0,i.jsx)(s.strong,{children:"submitted"})," within each priority level. Additionally, hovering over the ",(0,i.jsx)(s.strong,{children:"Current"})," label reveals the name of the most recent build, and this comparison can be used across milestones or versions to track how test cases are performing based on their assigned priorities."]}),"\n",(0,i.jsx)(s.p,{children:(0,i.jsx)(s.img,{src:t(41735).A+"",width:"1274",height:"604"})}),"\n",(0,i.jsx)(s.hr,{}),"\n",(0,i.jsx)(s.h3,{id:"test-case-create-velocity",children:"Test Case Create Velocity"}),"\n",(0,i.jsx)(s.p,{children:"Test Case Create Velocity refers to the rate at which test cases are being created over a defined period of time. It mainly shows the number of test cases created each day over the past 30 days. It helps to understand the number of test cases on specific dates, providing a date-wise breakdown of test case creation activity."}),"\n",(0,i.jsx)(s.p,{children:(0,i.jsx)(s.img,{src:t(91825).A+"",width:"1243",height:"608"})}),"\n",(0,i.jsx)(s.hr,{}),"\n",(0,i.jsx)(s.h3,{id:"scheduler-health",children:"Scheduler Health"}),"\n",(0,i.jsx)(s.p,{children:"Scheduler Health refers to the current status of the schedulers in an automation system."}),"\n",(0,i.jsx)(s.p,{children:"On the left side of the Scheduler Health section, the name of each scheduler is displayed. It shows whether the test cases scheduled in the last 10 runs were executed successfully or not."}),"\n",(0,i.jsxs)(s.p,{children:["If a scheduler shows a ",(0,i.jsx)(s.strong,{children:"hot pink"})," sign, it means that the test did not run.",(0,i.jsx)(s.br,{}),"\n","If a scheduler shows a ",(0,i.jsx)(s.strong,{children:"green"})," sign, it means the test was successfully executed."]}),"\n",(0,i.jsx)(s.p,{children:(0,i.jsx)(s.img,{src:t(93747).A+"",width:"1275",height:"216"})}),"\n",(0,i.jsx)(s.hr,{}),"\n",(0,i.jsx)(s.h3,{id:"orphaned-test-cases",children:"Orphaned Test Cases"}),"\n",(0,i.jsx)(s.p,{children:"Orphaned Test Cases are test cases that are no longer linked to any active or valid test set. They exist in the system but are not part of any current testing activity or structure."}),"\n",(0,i.jsx)(s.p,{children:(0,i.jsx)(s.img,{src:t(51867).A+"",width:"1261",height:"592"})}),"\n",(0,i.jsx)(s.hr,{}),"\n",(0,i.jsx)(s.h3,{id:"storage",children:"Storage"}),"\n",(0,i.jsxs)(s.p,{children:["Storage mainly shows how much server space is used and how much is still available. For example, ",(0,i.jsx)(s.strong,{children:"40.59 GB (84%)"})," is used, and ",(0,i.jsx)(s.strong,{children:"7.79 GB (16%)"})," of space is available."]}),"\n",(0,i.jsxs)(s.table,{children:[(0,i.jsx)(s.thead,{children:(0,i.jsxs)(s.tr,{children:[(0,i.jsx)(s.th,{children:"Used Storage"}),(0,i.jsx)(s.th,{children:"Available Storage"})]})}),(0,i.jsx)(s.tbody,{children:(0,i.jsxs)(s.tr,{children:[(0,i.jsx)(s.td,{children:(0,i.jsx)(s.img,{src:t(4645).A+"",width:"1257",height:"589"})}),(0,i.jsx)(s.td,{children:(0,i.jsx)(s.img,{src:t(81784).A+"",width:"1273",height:"585"})})]})})]}),"\n",(0,i.jsx)(s.hr,{})]})}function u(e={}){const{wrapper:s}={...(0,n.R)(),...e.components};return s?(0,i.jsx)(s,{...e,children:(0,i.jsx)(c,{...e})}):c(e)}},91825:(e,s,t)=>{t.d(s,{A:()=>r});const r=t.p+"assets/images/test-velocity-8a2d88489641ba30b0a7fdbc46ee6d21.png"},91856:(e,s,t)=>{t.d(s,{A:()=>r});const r=t.p+"assets/images/dashboard-node-a1c0f80423d5352db5f0698245a4289c.png"},93747:(e,s,t)=>{t.d(s,{A:()=>r});const r=t.p+"assets/images/scheduler-health-02ebfb3e2f29871be2410c98c9cef929.png"}}]);
"use strict";(self.webpackChunkzeuz_docs=self.webpackChunkzeuz_docs||[]).push([[3888],{28453:(e,t,i)=>{i.d(t,{R:()=>r,x:()=>a});var n=i(96540);const s={},o=n.createContext(s);function r(e){const t=n.useContext(o);return n.useMemo((function(){return"function"==typeof e?e(t):{...t,...e}}),[t,e])}function a(e){let t;return t=e.disableParentContext?"function"==typeof e.components?e.components(s):e.components||s:r(e.components),n.createElement(o.Provider,{value:t},e.children)}},94448:(e,t,i)=>{i.r(t),i.d(t,{assets:()=>c,contentTitle:()=>a,default:()=>d,frontMatter:()=>r,metadata:()=>n,toc:()=>l});const n=JSON.parse('{"id":"zeuz-node/actions/GUI Controls/actions-gui","title":"Graphical UI Control Actions","description":"Description","source":"@site/docs/zeuz-node/actions/GUI Controls/actions-gui.md","sourceDirName":"zeuz-node/actions/GUI Controls","slug":"/zeuz-node/actions/GUI Controls/actions-gui","permalink":"/docs/zeuz-node/actions/GUI Controls/actions-gui","draft":false,"unlisted":false,"tags":[],"version":"current","frontMatter":{"id":"actions-gui","title":"Graphical UI Control Actions"},"sidebar":"docsSidebar","previous":{"title":"Wait for Timer","permalink":"/docs/zeuz-node/actions/Common Actions/wait-for-timer"},"next":{"title":"OCR - Get text using coordinates","permalink":"/docs/zeuz-node/actions/GUI Controls/action-gui-controls-ocr-get-text-using-coords"}}');var s=i(74848),o=i(28453);const r={id:"actions-gui",title:"Graphical UI Control Actions"},a=void 0,c={},l=[{value:"Description",id:"description",level:2},{value:"Examples of Graphical UI Actions",id:"examples-of-graphical-ui-actions",level:2},{value:"1. <strong>Playback Recorded Events</strong>",id:"1-playback-recorded-events",level:3},{value:"2. <strong>Check for Element</strong>",id:"2-check-for-element",level:3},{value:"3. <strong>Click Element</strong>",id:"3-click-element",level:3},{value:"4. <strong>Click Element with OCR</strong>",id:"4-click-element-with-ocr",level:3},{value:"5. <strong>Click on Coordinates</strong>",id:"5-click-on-coordinates",level:3},{value:"6. <strong>Close Browser</strong>",id:"6-close-browser",level:3},{value:"7. <strong>Double Click Element</strong>",id:"7-double-click-element",level:3},{value:"8. <strong>Double Click Element with OCR</strong>",id:"8-double-click-element-with-ocr",level:3},{value:"9. <strong>Drag an element to a specific coordinates</strong>",id:"9-drag-an-element-to-a-specific-coordinates",level:3},{value:"10. <strong>Drag element by images</strong>",id:"10-drag-element-by-images",level:3},{value:"11. <strong>Enter Text</strong>",id:"11-enter-text",level:3},{value:"12. <strong>Execute hotkey</strong>",id:"12-execute-hotkey",level:3},{value:"13. <strong>Finding element from dropdown list</strong>",id:"13-finding-element-from-dropdown-list",level:3},{value:"14. <strong>Get Bounding Box</strong>",id:"14-get-bounding-box",level:3},{value:"15. <strong>Get Text using OCR with Coordinates</strong>",id:"15-get-text-using-ocr-with-coordinates",level:3},{value:"16. <strong>Get Text using OCR with Image</strong>",id:"16-get-text-using-ocr-with-image",level:3},{value:"17. <strong>Get Text using OCR with Text</strong>",id:"17-get-text-using-ocr-with-text",level:3},{value:"18. <strong>Hover over an element</strong>",id:"18-hover-over-an-element",level:3},{value:"19. <strong>Keystroke Chars</strong>",id:"19-keystroke-chars",level:3},{value:"20. <strong>Move mouse cursor</strong>",id:"20-move-mouse-cursor",level:3},{value:"21. <strong>Right Click Element</strong>",id:"21-right-click-element",level:3},{value:"22. <strong>Right Click Element with OCR</strong>",id:"22-right-click-element-with-ocr",level:3},{value:"23. <strong>Take Partial Screenshot</strong>",id:"23-take-partial-screenshot",level:3},{value:"24. <strong>Wait for an element to appear</strong>",id:"24-wait-for-an-element-to-appear",level:3},{value:"25. <strong>Wait for an element to disappear</strong>",id:"25-wait-for-an-element-to-disappear",level:3},{value:"26. <strong>Launch program by given program name</strong>",id:"26-launch-program-by-given-program-name",level:3}];function h(e){const t={a:"a",code:"code",h2:"h2",h3:"h3",li:"li",ol:"ol",p:"p",strong:"strong",ul:"ul",...(0,o.R)(),...e.components};return(0,s.jsxs)(s.Fragment,{children:[(0,s.jsx)(t.h2,{id:"description",children:"Description"}),"\n",(0,s.jsx)(t.p,{children:"Graphical User Interface (GUI) control actions are user interactions with apllication elements like buttons, menus, and text fields to perform tasks. These actions include clicking, hovering, typing, selecting, scrolling, and dragging, providing an intuitive way to navigate and operate software efficiently. They enhance usability by simplifying complex tasks into visual commands. In testing and automation, tools like Selenium or ZeuZ simulate these actions to ensure the application functions correctly and responds to user input."}),"\n",(0,s.jsx)(t.h2,{id:"examples-of-graphical-ui-actions",children:"Examples of Graphical UI Actions"}),"\n",(0,s.jsxs)(t.h3,{id:"1-playback-recorded-events",children:["1. ",(0,s.jsx)(t.strong,{children:"Playback Recorded Events"})]}),"\n",(0,s.jsxs)(t.p,{children:["Uploading ",(0,s.jsx)(t.code,{children:".zvt"})," files allows users to replay recorded interactions or scenarios within a software or testing tool. These files capture user actions like clicks, typing, and navigation, which the tool simulates in the same sequence during playback. By uploading the ",(0,s.jsx)(t.code,{children:".zvt"})," file, the tool executes the recorded actions, mimicking the original interactions and validating the application's response. This functionality is commonly used in test automation to ensure consistent execution of previously recorded tests, in bug reproduction to replicate issues as reported, and in training to demonstrate workflows. It streamlines repetitive tasks, enhances accuracy, and saves time, particularly in software testing and quality assurance processes."]}),"\n",(0,s.jsxs)(t.h3,{id:"2-check-for-element",children:["2. ",(0,s.jsx)(t.strong,{children:"Check for Element"})]}),"\n",(0,s.jsxs)(t.p,{children:["This action checks whether a specific element is visible on the screen and stores the result in a variable named ",(0,s.jsx)(t.strong,{children:'"check"'})," by default, or a custom name provided by the user. If the element is visible, the variable contains ",(0,s.jsx)(t.strong,{children:"True"}),"; otherwise, it contains ",(0,s.jsx)(t.strong,{children:"False"}),". The result can be used in conditional operations, such as ",(0,s.jsx)(t.code,{children:"if-else"})," statements, to guide workflow decisions. This action is particularly useful in automated testing and workflows to verify element visibility and dynamically respond to its presence."]}),"\n",(0,s.jsxs)(t.h3,{id:"3-click-element",children:["3. ",(0,s.jsx)(t.strong,{children:"Click Element"})]}),"\n",(0,s.jsx)(t.p,{children:"This action performs a single click on an uploaded image specified in the attachment section, using the image as a visual reference. Users can define the click position, such as the center or custom coordinates. It is useful for automating interactions with graphical elements, like buttons or icons, especially in scenarios where traditional element locators are unavailable. This allows precise and image-based interaction in workflows or automation tasks."}),"\n",(0,s.jsxs)(t.h3,{id:"4-click-element-with-ocr",children:["4. ",(0,s.jsx)(t.strong,{children:"Click Element with OCR"})]}),"\n",(0,s.jsxs)(t.p,{children:["This action uses Optical Charger Recognition (OCR) to find and click on specified text within an interface. Users define the text to search for and can choose a matching method-",(0,s.jsx)(t.strong,{children:"Match"})," for high accuracy, ",(0,s.jsx)(t.strong,{children:"Partial Match"})," for moderate similarity, or ",(0,s.jsx)(t.strong,{children:"Loose Match"})," for greater flexibility with OCR imperfections. For instance, if the text specified is ",(0,s.jsx)(t.strong,{children:'"E-Transfer Total"'})," and OCR detects ",(0,s.jsx)(t.strong,{children:'"Transfer Tol"'}),", the method influences the matching score, with ",(0,s.jsx)(t.strong,{children:"Loose Match"})," accepting weaker similarities. This action is ideal for automating text-based interactions, offering flexibility in environments where text recognition may vary."]}),"\n",(0,s.jsxs)(t.h3,{id:"5-click-on-coordinates",children:["5. ",(0,s.jsx)(t.strong,{children:"Click on Coordinates"})]}),"\n",(0,s.jsxs)(t.p,{children:["This action executes a left-click at a specific location on the screen based on the provided ",(0,s.jsx)(t.strong,{children:"X, Y coordinates"}),", allowing precise interaction with the interface. Users input the desired coordinates, such as ",(0,s.jsx)(t.code,{children:"271, 1051"}),", and the tool clicks at the specified point. It is particularly useful for interacting with elements that cannot be identified programmatically, such as fixed-position items or non-started GUIs. This action is ideal for automating tasks in graphic-based interfaces or simulating user clicks with precision in testing or workflow automation scenarios."]}),"\n",(0,s.jsxs)(t.h3,{id:"6-close-browser",children:["6. ",(0,s.jsx)(t.strong,{children:"Close Browser"})]}),"\n",(0,s.jsx)(t.p,{children:"The action to close a running program terminates an active application or process on the system, either gracefully or forcibly. Users specify the program by its name, window title, or process ID, and the action attempts to safely close it, allowing any ongoing tasks to complete. If the program does not respond, it can be forcibly terminated. This action is useful for managing workflows, freeing up system resources, or automating tasks that require starting and stopping applications."}),"\n",(0,s.jsxs)(t.h3,{id:"7-double-click-element",children:["7. ",(0,s.jsx)(t.strong,{children:"Double Click Element"})]}),"\n",(0,s.jsx)(t.p,{children:"This action performs a double-click on a specified image uploaded in the attachment section, using the image as a visual reference to locate the target on the screen. Users can customize the click position, such as the center or specific coordinates. It is ideal for automating tasks involving graphical elements like icons or files, especially in non-standard interfaces or dynamic environments where precise image-based interactions are required."}),"\n",(0,s.jsxs)(t.h3,{id:"8-double-click-element-with-ocr",children:["8. ",(0,s.jsx)(t.strong,{children:"Double Click Element with OCR"})]}),"\n",(0,s.jsxs)(t.p,{children:["This action allows users to locate specified text on the screen using OCR and perform a double-click on it. The user specifies the text to be targeted, and the tool searches for it on the interface. If the exact text is not found, optional parameters like matching methods can be used to refine the search. The ",(0,s.jsx)(t.strong,{children:"Match"})," method ensures high accuracy by requiring strong similarity, while ",(0,s.jsx)(t.strong,{children:"Partial Match"})," allows moderate similarity, and ",(0,s.jsx)(t.strong,{children:"Loose Match"})," permits weaker similarities for more flexibility. For instance, if the specified text is ",(0,s.jsx)(t.strong,{children:'"E-Transfer Total"'})," and OCR detects ",(0,s.jsx)(t.strong,{children:"Transfer Tol"}),", the method selected influences the matching score, with ",(0,s.jsx)(t.strong,{children:"Loose Match"})," producing the highest tolerance. This action is particularly useful for automating interactions with text-based elements in dynamic environments, providing both precision and adaptability to handle variations or OCR imperfections."]}),"\n",(0,s.jsxs)(t.h3,{id:"9-drag-an-element-to-a-specific-coordinates",children:["9. ",(0,s.jsx)(t.strong,{children:"Drag an element to a specific coordinates"})]}),"\n",(0,s.jsx)(t.p,{children:"The drag action involves moving an element from a defined position on a source image (e.g., center, top-left, or custom point) to a target location specified by X, Y coordinates. It simulates user interaction by clicking and holding at the source position, dragging the element, and releasing it at the destination. This action is commonly used in test automation to verify drag-and-drop functionalities in web or graphical interfaces, ensuring the UI responds correctly to user inputs. Tools like Selenium or ZeuZ support such interactions for robust testing."}),"\n",(0,s.jsx)(t.p,{children:(0,s.jsx)(t.a,{href:"https://drive.google.com/file/d/11YfBRtlP3xBOVH4a9s_68Pz7eGurWopr/view?usp=sharing",children:"Video - Drag an element to a specific coordinates"})}),"\n",(0,s.jsxs)(t.h3,{id:"10-drag-element-by-images",children:["10. ",(0,s.jsx)(t.strong,{children:"Drag element by images"})]}),"\n",(0,s.jsxs)(t.p,{children:["The drag action allows moving an element from a defined position on a ",(0,s.jsx)(t.strong,{children:"source image"})," to a specific position on a ",(0,s.jsx)(t.strong,{children:"destination image"}),", simulating a user interaction. The starting point on the source image can be set, such as the ",(0,s.jsx)(t.strong,{children:"center"}),", ",(0,s.jsx)(t.strong,{children:"top-left"}),", or any custom coordinate within the image."]}),"\n",(0,s.jsx)(t.p,{children:(0,s.jsx)(t.a,{href:"https://drive.google.com/file/d/11YfBRtlP3xBOVH4a9s_68Pz7eGurWopr/view?usp=sharing",children:"Video - Drag element by images"})}),"\n",(0,s.jsx)(t.p,{children:"The process involves clicking and holding the element at the specified position on the source image, dragging it across the interface, and releasing it at the target location on the destination image. This action is typically used to validate drag-and-drop functionalities where an element must move from one visual context to another, ensuring accurate UI responses."}),"\n",(0,s.jsx)(t.p,{children:"Automation tools like ZeuZ often include this feature to test such interactions efficiently."}),"\n",(0,s.jsxs)(t.h3,{id:"11-enter-text",children:["11. ",(0,s.jsx)(t.strong,{children:"Enter Text"})]}),"\n",(0,s.jsx)(t.p,{children:'This action is used to input text into a specified location, simulating user interaction with a text field or input area. The location is typically defined by coordinates, a specific element selector, or an input box identifier on the interface. The process involves focusing on the target field, entering the desired text, and optionally performing additional steps like pressing "Enter" or moving to the next field.'}),"\n",(0,s.jsx)(t.p,{children:"This action is commonly used in test automation to validate text entry functionality in forms, search bars, or other input areas, ensuring that the application processes the input accurately. Tools like ZeuZ support this action for seamless and precise text entry during testing."}),"\n",(0,s.jsxs)(t.h3,{id:"12-execute-hotkey",children:["12. ",(0,s.jsx)(t.strong,{children:"Execute hotkey"})]}),"\n",(0,s.jsxs)(t.p,{children:["This action simulates executing a hotkey sequence, which is a combination of keys pressed simultaneously to perform specific tasks. The hotkey sequence is defined using keys seperated by the plus (",(0,s.jsx)(t.code,{children:"+"}),") symbol, such as ",(0,s.jsx)(t.strong,{children:"Ctrl + S"}),", ",(0,s.jsx)(t.strong,{children:"Alt + Tab"}),", or ",(0,s.jsx)(t.strong,{children:"Ctrl + Shift + S"}),", and supports various valid key combinations detailed in the ",(0,s.jsx)(t.strong,{children:"hotkey_arguments"})," documentation. Additionally, the action allows repetition of the same hotkey sequence by specifying the number of times it should be executed using the ",(0,s.jsx)(t.strong,{children:"count"})," parameter. For example, setting ",(0,s.jsx)(t.code,{children:"count = 3"})," repeats the hotkey action three times. This functionality is commonly used in automation testing to validate the behavior of keyboard shortcuts, ensuring that specific key combinations trigger the intended actions, such as saving a file, switching between applications, or invoking advanced commands. Tools like ZeuZ incorporate this feature to streamline and verify keyboard-based interactions efficiently."]}),"\n",(0,s.jsxs)(t.h3,{id:"13-finding-element-from-dropdown-list",children:["13. ",(0,s.jsx)(t.strong,{children:"Finding element from dropdown list"})]}),"\n",(0,s.jsxs)(t.p,{children:["This action automates scrolling within a listbox to locate a desired element, such as an image, by repeatedly scrolling and checking for its presence. The ",(0,s.jsx)(t.strong,{children:"maximum tries"})," parameter limits the number of scroll attempts, ensuring the action stops after a specified number (e.g., 10) if the element is not found. If located, the scrolling stops immediately. This functionality is useful for navigating dynamic content or long lists in automation, with tools like ZeuZ enabling efficient testing of scrollable interfaces."]}),"\n",(0,s.jsxs)(t.h3,{id:"14-get-bounding-box",children:["14. ",(0,s.jsx)(t.strong,{children:"Get Bounding Box"})]}),"\n",(0,s.jsxs)(t.p,{children:["This action retrieves the bounding box parameters of an image displayed on the screen, such as the ",(0,s.jsx)(t.strong,{children:"X"})," and ",(0,s.jsx)(t.strong,{children:"Y"})," ",(0,s.jsx)(t.strong,{children:"coordinates"}),", ",(0,s.jsx)(t.strong,{children:"width"}),", and ",(0,s.jsx)(t.strong,{children:"height"}),". The image to be located must be uploaded in the attachment section. The action identifies the image's position and dimensions and stores these parameters in a variable."]}),"\n",(0,s.jsxs)(t.p,{children:["You can specify a custom variable name to store the parameters; by default, the variable is named ",(0,s.jsx)(t.strong,{children:"cords"}),". The variable is structured as a list, where you can access individual parameters by their index:"]}),"\n",(0,s.jsxs)(t.ul,{children:["\n",(0,s.jsxs)(t.li,{children:[(0,s.jsx)(t.strong,{children:"cords[0]:"})," X coordinate"]}),"\n",(0,s.jsxs)(t.li,{children:[(0,s.jsx)(t.strong,{children:"cords[1]:"})," Y coordinate"]}),"\n",(0,s.jsxs)(t.li,{children:[(0,s.jsx)(t.strong,{children:"cords[2]:"})," Width"]}),"\n",(0,s.jsxs)(t.li,{children:[(0,s.jsx)(t.strong,{children:"cords[3]:"})," Height"]}),"\n"]}),"\n",(0,s.jsx)(t.p,{children:"This action is particularly useful in automation for validating or interacting with specific UI elements based on their location and size. Tools like ZeuZ support this feature to enable precise identification and interaction with visual elements during testing."}),"\n",(0,s.jsxs)(t.h3,{id:"15-get-text-using-ocr-with-coordinates",children:["15. ",(0,s.jsx)(t.strong,{children:"Get Text using OCR with Coordinates"})]}),"\n",(0,s.jsxs)(t.p,{children:["This action lets one crop a specific portion of a screenshot and extract the text from that area by defining the ",(0,s.jsx)(t.strong,{children:"top"}),", ",(0,s.jsx)(t.strong,{children:"left"}),", ",(0,s.jsx)(t.strong,{children:"bottom"}),", and ",(0,s.jsx)(t.strong,{children:"right"})," coordinates to create a bounding box around the desired text. For example, to extract the date of creation of maps, the coordinates that enclose the text would need to be specified. A variable name must also be provided to store the extracted text, which will be returned as a variable. This action is useful for automating the extraction of specific information from screenshots during testing, and tools like ZeuZ can facilitate this process efficiently."]}),"\n",(0,s.jsxs)(t.h3,{id:"16-get-text-using-ocr-with-image",children:["16. ",(0,s.jsx)(t.strong,{children:"Get Text using OCR with Image"})]}),"\n",(0,s.jsxs)(t.p,{children:["This action enables the extraction of text based on its positional relationship to a provided image. The image must be attached in the attachment section, and the direction of the text relative to the image-",(0,s.jsx)(t.strong,{children:"left"}),", ",(0,s.jsx)(t.strong,{children:"right"}),", ",(0,s.jsx)(t.strong,{children:"top"}),", or ",(0,s.jsx)(t.strong,{children:"bottom"}),"-needs to be specified. An optional ",(0,s.jsx)(t.strong,{children:"text gap"})," parameter, given as an integer, can further refine the extraction by indicating the proximity of the text to the image."]}),"\n",(0,s.jsx)(t.p,{children:"A variable name must also be provided to store the extracted text, which will be returned as output. This action is useful in scenarios where text extraction needs to be contextualized by its placement relative to an image, allowing for precise data retrieval during automation or testing processes. Tools like ZeuZ can efficiently implement this action for accurate text extraction tasks."}),"\n",(0,s.jsxs)(t.h3,{id:"17-get-text-using-ocr-with-text",children:["17. ",(0,s.jsx)(t.strong,{children:"Get Text using OCR with Text"})]}),"\n",(0,s.jsxs)(t.p,{children:["This action extracts text based on its position relative to a specified text string, which is located using Optical Character Recognition (OCR). Parameters such as ",(0,s.jsx)(t.strong,{children:"method"})," and ",(0,s.jsx)(t.strong,{children:"threshold"})," can be used to fine-tune the search for the reference text. After locating it, the action extracts the desired text in a specified direction-",(0,s.jsx)(t.strong,{children:"left"}),", ",(0,s.jsx)(t.strong,{children:"right"}),", ",(0,s.jsx)(t.strong,{children:"top"}),", or ",(0,s.jsx)(t.strong,{children:"bottom"}),". An optional ",(0,s.jsx)(t.strong,{children:"text gap"})," parameter allows further precision by defining the distance of the desired text from the reference. A variable name must be provided to store the extracted text, making this action ideal for automation scenarios requiring context-sensitive text retrieval. Tools like ZeuZ efficiently handle such OCR-based tasks."]}),"\n",(0,s.jsxs)(t.h3,{id:"18-hover-over-an-element",children:["18. ",(0,s.jsx)(t.strong,{children:"Hover over an element"})]}),"\n",(0,s.jsxs)(t.p,{children:["This action simulates hovering the mouse over a specified element on the screen, represented by an image. The position on the image where the hover occurs can be defined, such as the ",(0,s.jsx)(t.strong,{children:"center"}),", ",(0,s.jsx)(t.strong,{children:"top-left"}),", or any custom point within the image. For example, selecting the ",(0,s.jsx)(t.strong,{children:"center"})," will move the mouse pointer to the middle of the image and perform the hover action."]}),"\n",(0,s.jsx)(t.p,{children:"This action is commonly used to trigger hover-based UI behaviors, such as displaying tooltips, dropdown menus, or highlighting elements, during testing or automation. Tools like ZeuZ support this functionality to validate hover interactions and ensure the UI responds as expected."}),"\n",(0,s.jsxs)(t.h3,{id:"19-keystroke-chars",children:["19. ",(0,s.jsx)(t.strong,{children:"Keystroke Chars"})]}),"\n",(0,s.jsx)(t.p,{children:"This action simulates typing sequential characters or strings into an input field or text area. The user specifies the text to be typed, and the action types each character in sequence. Additionally, a delay interval can be set between typing each character to mimic natural typing speed, with the default delay set to 0 (no delay)."}),"\n",(0,s.jsx)(t.p,{children:"This action is commonly used in automation for scenarios requiring text input, such as form filling or search functionality, ensuring accurate and realistic simulation of user interactions. Tools like ZeuZ support this feature for precise and customizable input automation."}),"\n",(0,s.jsxs)(t.h3,{id:"20-move-mouse-cursor",children:["20. ",(0,s.jsx)(t.strong,{children:"Move mouse cursor"})]}),"\n",(0,s.jsxs)(t.p,{children:["This action moves the mouse cursor to a specified coordinate on the screen, either relative to its current position or as an absolute position, based on the ",(0,s.jsx)(t.strong,{children:"relative"})," parameter. Setting ",(0,s.jsx)(t.strong,{children:"relative = true"})," moves the cursor relative to its current location, while ",(0,s.jsx)(t.strong,{children:"relative = false"})," moves it to an absolute screen coordinate."]}),"\n",(0,s.jsxs)(t.p,{children:["An optional ",(0,s.jsx)(t.strong,{children:"duration"}),' parameter, specified in seconds (as a float), can simulate natural cursor movement by creating a delay as the cursor transitions from one position to another. This action is useful in automation for replicating human-like cursor movements and interactions with specific screen elements. Tags like "Mouse" and "Cursor" categorize this functionality for easy reference in tools like ZeuZ.']}),"\n",(0,s.jsxs)(t.h3,{id:"21-right-click-element",children:["21. ",(0,s.jsx)(t.strong,{children:"Right Click Element"})]}),"\n",(0,s.jsxs)(t.p,{children:["This action simulates a right-click on a specified image provided in the attachment section. The click can be performed at a defined position on the image, such as the ",(0,s.jsx)(t.strong,{children:"center"}),", ",(0,s.jsx)(t.strong,{children:"top-left"}),", or a custom coordinate within the image. For example, selecting ",(0,s.jsx)(t.strong,{children:"center"})," will perform the right-click at the middle of the image."]}),"\n",(0,s.jsx)(t.p,{children:"This functionality is commonly used in automation testing to interact with context menus or trigger actions associated with a right-click on specific UI elements. Tools like ZeuZ support this action for precise and effective interaction with image-based elements."}),"\n",(0,s.jsxs)(t.h3,{id:"22-right-click-element-with-ocr",children:["22. ",(0,s.jsx)(t.strong,{children:"Right Click Element with OCR"})]}),"\n",(0,s.jsxs)(t.p,{children:["This action uses Optical Character Recognition (OCR) to locate specified text on the screen and perform a right-click on it. The user specifies the text to be clicked and can adjust optional parameters such as ",(0,s.jsx)(t.strong,{children:"method"})," and ",(0,s.jsx)(t.strong,{children:"threshold"})," to refine the search process."]}),"\n",(0,s.jsxs)(t.ul,{children:["\n",(0,s.jsxs)(t.li,{children:[(0,s.jsx)(t.strong,{children:"Method:"})," Determines how closely the identified text must match the specified text. Options include:","\n",(0,s.jsxs)(t.ul,{children:["\n",(0,s.jsxs)(t.li,{children:[(0,s.jsx)(t.strong,{children:"Match:"})," Requires strong similarity for a high score."]}),"\n",(0,s.jsxs)(t.li,{children:[(0,s.jsx)(t.strong,{children:"Partial Match:"})," Allows moderate similarity, producing scores in between."]}),"\n",(0,s.jsxs)(t.li,{children:[(0,s.jsx)(t.strong,{children:"Loose Match:"}),' Accepts weaker similarity, resulting in higher scores for less exact matches. For example, if the specified text is "E-Transfer Total" and OCR identifies "Transfer Tol", the ',(0,s.jsx)(t.strong,{children:"Match"})," method may give a score of 86, while ",(0,s.jsx)(t.strong,{children:"Loose Match"})," could score 92."]}),"\n"]}),"\n"]}),"\n",(0,s.jsxs)(t.li,{children:[(0,s.jsx)(t.strong,{children:"Threshold:"})," Sets a minimum score for text matching to qualify for a click. For strict conditions, a thrshold of ",(0,s.jsx)(t.strong,{children:"90"})," ensures only text with a matching score of 90 or higher is clicked. For exact matches, a threshold of ",(0,s.jsx)(t.strong,{children:"100"})," is used."]}),"\n"]}),"\n",(0,s.jsx)(t.p,{children:"This action is useful for automation tasks requiring interaction with text elements detected dynamically through OCR, allowing customization based on accuracy and flexibility needs. Tools like ZeuZ enable precise implementation of such text-based interactions."}),"\n",(0,s.jsxs)(t.h3,{id:"23-take-partial-screenshot",children:["23. ",(0,s.jsx)(t.strong,{children:"Take Partial Screenshot"})]}),"\n",(0,s.jsx)(t.p,{children:"This action captures a screenshot of a specific region of the currently active screen rather than the entire screen. To perform this, the user must provide:"}),"\n",(0,s.jsxs)(t.ol,{children:["\n",(0,s.jsxs)(t.li,{children:[(0,s.jsx)(t.strong,{children:"Full Path:"})," The file path and name where the screenshot will be saved."]}),"\n",(0,s.jsxs)(t.li,{children:[(0,s.jsx)(t.strong,{children:"Bounding Box Parameters:"})," Four integers defining the region to capture:","\n",(0,s.jsxs)(t.ul,{children:["\n",(0,s.jsxs)(t.li,{children:[(0,s.jsx)(t.strong,{children:"X Coordinate:"})," The horizontal position of the top-left corner."]}),"\n",(0,s.jsxs)(t.li,{children:[(0,s.jsx)(t.strong,{children:"Y Coordinate:"})," The vertical position of the top-left corner."]}),"\n",(0,s.jsxs)(t.li,{children:[(0,s.jsx)(t.strong,{children:"Width:"})," The width of the region to capture."]}),"\n",(0,s.jsxs)(t.li,{children:[(0,s.jsx)(t.strong,{children:"Height:"})," The height of the region to capture."]}),"\n"]}),"\n"]}),"\n"]}),"\n",(0,s.jsx)(t.p,{children:"This action is useful for isolating and saving a specific portion of the screen, such as a dialog box, menu, or area of interest, during automation or testing processes. Tools like ZeuZ make this process efficient by supporting precise region-based screenshot functionality."}),"\n",(0,s.jsxs)(t.h3,{id:"24-wait-for-an-element-to-appear",children:["24. ",(0,s.jsx)(t.strong,{children:"Wait for an element to appear"})]}),"\n",(0,s.jsxs)(t.p,{children:["This action searches for a specified image attached in the test session and waits for it to appear on the screen. The image must be uploaded in the attachment section, and the filename (e.g., ",(0,s.jsx)(t.strong,{children:"file_name.png"}),") should be mentioned explicitly."]}),"\n",(0,s.jsxs)(t.p,{children:["An optional ",(0,s.jsx)(t.strong,{children:"wait"})," parameter can be set to specify the maximum time (in seconds) to wait for the image to appear. By default, the action waits for ",(0,s.jsx)(t.strong,{children:"10 seconds"}),". If the image appears within the defined time, the action proceeds; otherwise, it times out."]}),"\n",(0,s.jsx)(t.p,{children:"This functionality is commonly used in automation testing to verify the presence of specific visual elements, ensuring the application displays the required UI components within a set timeframe. Tools like ZeuZ provide this feature to facilitate efficient image-based validation."}),"\n",(0,s.jsxs)(t.h3,{id:"25-wait-for-an-element-to-disappear",children:["25. ",(0,s.jsx)(t.strong,{children:"Wait for an element to disappear"})]}),"\n",(0,s.jsxs)(t.p,{children:["This action monitors the screen to detect when a specified image, provided in the attachment section, disappears. The image must be uploaded, and its filename (e.g., ",(0,s.jsx)(t.strong,{children:"file_name.png"}),") should be specified."]}),"\n",(0,s.jsxs)(t.p,{children:["An optional ",(0,s.jsx)(t.strong,{children:"wait"})," parameter allows the user to set the maximum time (in seconds) to wait for the image's disappearance. By default, the action waits for ",(0,s.jsx)(t.strong,{children:"10 seconds"}),". If the image disappears within the specified time, the action proceeds; otherwise, it times out."]}),"\n",(0,s.jsx)(t.p,{children:"This functionality is particularly useful in automation testing to confirm that certain visual elements, such as loading screens, notifications, or temporary UI elements, are removed as expected. Tools like ZeuZ enable this feature to ensure dynamic elements behave correctly during tests."}),"\n",(0,s.jsxs)(t.h3,{id:"26-launch-program-by-given-program-name",children:["26. ",(0,s.jsx)(t.strong,{children:"Launch program by given program name"})]}),"\n",(0,s.jsx)(t.p,{children:"This action is used to launch a specified program or application on the system. The user needs to provide the path to the program's executable file, ensuring the correct application is targeted. Optionally, additional parameters or arguments can be included if the program supports command-line inputs."}),"\n",(0,s.jsx)(t.p,{children:"This action is particularly useful in automation scenarios where specific applications need to be opened as part of the testing or workflow process. Tools like ZeuZ facilitate this by enabling seamless integration and execution of programs during test sessions."}),"\n",(0,s.jsx)(t.p,{children:(0,s.jsx)(t.a,{href:"https://drive.google.com/file/d/1saADpTTKdwkEac49KtY93KHqkqowkeGm/view?usp=sharing",children:"Video - Launch program by given program name"})})]})}function d(e={}){const{wrapper:t}={...(0,o.R)(),...e.components};return t?(0,s.jsx)(t,{...e,children:(0,s.jsx)(h,{...e})}):h(e)}}}]);